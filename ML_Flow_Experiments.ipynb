{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "collapsed": true,
     "inputWidgets": {},
     "nuid": "138c8054-3bbb-487d-9a70-0568f12b4c32",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting yfinance\n  Downloading yfinance-0.2.66-py2.py3-none-any.whl.metadata (6.0 kB)\nRequirement already satisfied: pandas>=1.3.0 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2.2.3)\nRequirement already satisfied: numpy>=1.16.5 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2.1.3)\nRequirement already satisfied: requests>=2.31 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2.32.3)\nCollecting multitasking>=0.0.7 (from yfinance)\n  Downloading multitasking-0.0.12.tar.gz (19 kB)\n  Preparing metadata (setup.py): started\n  Preparing metadata (setup.py): finished with status 'done'\nRequirement already satisfied: platformdirs>=2.0.0 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (3.10.0)\nRequirement already satisfied: pytz>=2022.5 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (2024.1)\nCollecting frozendict>=2.3.4 (from yfinance)\n  Downloading frozendict-2.4.6-py312-none-any.whl.metadata (23 kB)\nCollecting peewee>=3.16.2 (from yfinance)\n  Downloading peewee-3.18.3.tar.gz (3.0 MB)\n\u001B[?25l     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/3.0 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m3.0/3.0 MB\u001B[0m \u001B[31m59.6 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25h  Installing build dependencies: started\n  Installing build dependencies: finished with status 'done'\n  Getting requirements to build wheel: started\n  Getting requirements to build wheel: finished with status 'done'\n  Preparing metadata (pyproject.toml): started\n  Preparing metadata (pyproject.toml): finished with status 'done'\nRequirement already satisfied: beautifulsoup4>=4.11.1 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (4.12.3)\nCollecting curl_cffi>=0.7 (from yfinance)\n  Downloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (13 kB)\nRequirement already satisfied: protobuf>=3.19.0 in /databricks/python3/lib/python3.12/site-packages (from yfinance) (5.29.4)\nCollecting websockets>=13.0 (from yfinance)\n  Downloading websockets-15.0.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl.metadata (6.8 kB)\nRequirement already satisfied: soupsieve>1.2 in /databricks/python3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\nRequirement already satisfied: cffi>=1.12.0 in /databricks/python3/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (1.17.1)\nRequirement already satisfied: certifi>=2024.2.2 in /databricks/python3/lib/python3.12/site-packages (from curl_cffi>=0.7->yfinance) (2025.1.31)\nRequirement already satisfied: python-dateutil>=2.8.2 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\nRequirement already satisfied: tzdata>=2022.7 in /databricks/python3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2024.1)\nRequirement already satisfied: charset-normalizer<4,>=2 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.3.2)\nRequirement already satisfied: idna<4,>=2.5 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /databricks/python3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.3.0)\nRequirement already satisfied: pycparser in /databricks/python3/lib/python3.12/site-packages (from cffi>=1.12.0->curl_cffi>=0.7->yfinance) (2.21)\nRequirement already satisfied: six>=1.5 in /usr/lib/python3/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.0->yfinance) (1.16.0)\nDownloading yfinance-0.2.66-py2.py3-none-any.whl (123 kB)\nDownloading curl_cffi-0.13.0-cp39-abi3-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (7.9 MB)\n\u001B[?25l   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m0.0/7.9 MB\u001B[0m \u001B[31m?\u001B[0m eta \u001B[36m-:--:--\u001B[0m\r\u001B[2K   \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m7.9/7.9 MB\u001B[0m \u001B[31m87.9 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n\u001B[?25hDownloading frozendict-2.4.6-py312-none-any.whl (16 kB)\nDownloading websockets-15.0.1-cp312-cp312-manylinux_2_17_aarch64.manylinux2014_aarch64.whl (183 kB)\nBuilding wheels for collected packages: multitasking, peewee\n  Building wheel for multitasking (setup.py): started\n  Building wheel for multitasking (setup.py): finished with status 'done'\n  Created wheel for multitasking: filename=multitasking-0.0.12-py3-none-any.whl size=15548 sha256=e69ff296f53af07158f59ff8cb6c09975a2e517c0b22494868da74df0802ca98\n  Stored in directory: /home/spark-dadaf446-fcf0-4d22-ba37-c2/.cache/pip/wheels/cc/bd/6f/664d62c99327abeef7d86489e6631cbf45b56fbf7ef1d6ef00\n  Building wheel for peewee (pyproject.toml): started\n  Building wheel for peewee (pyproject.toml): finished with status 'done'\n  Created wheel for peewee: filename=peewee-3.18.3-cp312-cp312-linux_aarch64.whl size=909448 sha256=8b5ae820df52f448f98201a46d9ef6c0e6225dfd30f216767a0f02a27e7e548e\n  Stored in directory: /home/spark-dadaf446-fcf0-4d22-ba37-c2/.cache/pip/wheels/e2/48/b6/675a31c56e50b8b343e1ffbb1d9209f0d95025e2cfa0bbeeed\nSuccessfully built multitasking peewee\nInstalling collected packages: peewee, multitasking, websockets, frozendict, curl_cffi, yfinance\nSuccessfully installed curl_cffi-0.13.0 frozendict-2.4.6 multitasking-0.0.12 peewee-3.18.3 websockets-15.0.1 yfinance-0.2.66\n\u001B[43mNote: you may need to restart the kernel using %restart_python or dbutils.library.restartPython() to use updated packages.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "#pip install yfinance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "d04ea285-dbcb-4272-bb76-4d3a7033e87c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Importar librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "feed5d6a-f591-4bca-8058-36cffd0d6a3a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "import yfinance as yf \n",
    "import pandas as pd \n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "from scipy.stats import randint\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from mlflow.models.signature import infer_signature"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "57dac1bf-9e37-4ae7-a4bd-be2f7a6bb870",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Cargar base de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "bd6c2137-a128-4cf8-855b-eb269118a8a4",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Ticker</th>\n",
       "      <th>variacion_relativa</th>\n",
       "      <th>variacion_porcentual</th>\n",
       "      <th>variacion_logaritmica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28184</th>\n",
       "      <td>2025-10-20 00:00:00-04:00</td>\n",
       "      <td>721.190002</td>\n",
       "      <td>733.770020</td>\n",
       "      <td>720.179993</td>\n",
       "      <td>732.169983</td>\n",
       "      <td>732.169983</td>\n",
       "      <td>8900200</td>\n",
       "      <td>META</td>\n",
       "      <td>1.021272</td>\n",
       "      <td>2.127155</td>\n",
       "      <td>0.021048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28185</th>\n",
       "      <td>2025-10-21 00:00:00-04:00</td>\n",
       "      <td>736.020020</td>\n",
       "      <td>738.500000</td>\n",
       "      <td>728.750000</td>\n",
       "      <td>733.270020</td>\n",
       "      <td>733.270020</td>\n",
       "      <td>7647300</td>\n",
       "      <td>META</td>\n",
       "      <td>1.001502</td>\n",
       "      <td>0.150243</td>\n",
       "      <td>0.001501</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28186</th>\n",
       "      <td>2025-10-22 00:00:00-04:00</td>\n",
       "      <td>733.830017</td>\n",
       "      <td>740.599976</td>\n",
       "      <td>724.030029</td>\n",
       "      <td>733.409973</td>\n",
       "      <td>733.409973</td>\n",
       "      <td>8734500</td>\n",
       "      <td>META</td>\n",
       "      <td>1.000191</td>\n",
       "      <td>0.019086</td>\n",
       "      <td>0.000191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28187</th>\n",
       "      <td>2025-10-23 00:00:00-04:00</td>\n",
       "      <td>734.700012</td>\n",
       "      <td>742.409973</td>\n",
       "      <td>733.099976</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>734.000000</td>\n",
       "      <td>9856000</td>\n",
       "      <td>META</td>\n",
       "      <td>1.000804</td>\n",
       "      <td>0.080450</td>\n",
       "      <td>0.000804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28188</th>\n",
       "      <td>2025-10-24 00:00:00-04:00</td>\n",
       "      <td>736.789978</td>\n",
       "      <td>741.210022</td>\n",
       "      <td>731.150024</td>\n",
       "      <td>738.359985</td>\n",
       "      <td>738.359985</td>\n",
       "      <td>9151300</td>\n",
       "      <td>META</td>\n",
       "      <td>1.005940</td>\n",
       "      <td>0.594003</td>\n",
       "      <td>0.005922</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           Date  ...  variacion_logaritmica\n",
       "28184 2025-10-20 00:00:00-04:00  ...               0.021048\n",
       "28185 2025-10-21 00:00:00-04:00  ...               0.001501\n",
       "28186 2025-10-22 00:00:00-04:00  ...               0.000191\n",
       "28187 2025-10-23 00:00:00-04:00  ...               0.000804\n",
       "28188 2025-10-24 00:00:00-04:00  ...               0.005922\n",
       "\n",
       "[5 rows x 11 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Definicion base de datos\n",
    "def df_yf_tidy( \n",
    "\n",
    "    tickers, \n",
    "\n",
    "    start=None, \n",
    "\n",
    "    end=None, \n",
    "\n",
    "    interval=\"1d\", \n",
    "\n",
    "    auto_adjust=False,  # Se mantiene False para conservar \"Adj Close\" y así mantener las 6 columnas \n",
    "\n",
    "): \n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    Devuelve un DataFrame 'largo' con múltiples tickers     \n",
    "\n",
    "    Índice por fecha y columna 'Ticker' para identificar. \n",
    "\n",
    "    \"\"\" \n",
    "\n",
    "    cols = [\"Open\", \"High\", \"Low\", \"Close\", \"Adj Close\", \"Volume\"] \n",
    "\n",
    "    frames = [] \n",
    "\n",
    " \n",
    "\n",
    "    for t in tickers: \n",
    "\n",
    "        h = yf.Ticker(t).history( \n",
    "\n",
    "            start=start, end=end, interval=interval, auto_adjust=auto_adjust \n",
    "\n",
    "        ) \n",
    "\n",
    "        if h.empty: \n",
    "\n",
    "            continue \n",
    "\n",
    "        for c in cols: \n",
    "\n",
    "            if c not in h.columns: \n",
    "\n",
    "                h[c] = pd.NA \n",
    "\n",
    "        out = h[cols].copy() \n",
    "\n",
    "        out[\"Ticker\"] = t \n",
    "\n",
    "        frames.append(out.reset_index())  # 'Date' pasa a columna \n",
    "\n",
    " \n",
    "\n",
    "    if not frames: \n",
    "\n",
    "        return pd.DataFrame(columns=[\"Date\"] + cols + [\"Ticker\"]) \n",
    "\n",
    " \n",
    "\n",
    "    df = pd.concat(frames, ignore_index=True) \n",
    "\n",
    "    # Orden de columnas \n",
    "\n",
    "    df = df[[\"Date\"] + cols + [\"Ticker\"]] \n",
    "\n",
    "    return df \n",
    "\n",
    " \n",
    "\n",
    "#Uso para crear base de datos. \n",
    "\n",
    "tickers = [\"AAPL\", \"MSFT\", \"AMZN\", \"GOOGL\", \"META\"] \n",
    "\n",
    "df = df_yf_tidy(tickers, start=\"2000-01-01\", end=\"2025-10-25\", interval=\"1d\") \n",
    "\n",
    " \n",
    "\n",
    "\n",
    "# Variación relativa \n",
    "\n",
    "df[\"variacion_relativa\"] = df[\"Adj Close\"] / df[\"Adj Close\"].shift(1) \n",
    "\n",
    "# Variación porcentual (en %) \n",
    "\n",
    "df[\"variacion_porcentual\"] = (df[\"Adj Close\"].pct_change()) * 100 \n",
    "\n",
    "# Variación logarítmica (en valores decimales) \n",
    "\n",
    "df[\"variacion_logaritmica\"] = np.log(df[\"Adj Close\"]).diff() \n",
    "\n",
    "df.tail() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "02a5e387-ac78-4688-b0cc-d73d4d25d0bb",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [],
   "source": [
    "#Separacion de variables independientes y dependiente\n",
    "df.dropna(inplace=True)\n",
    "X = df[['Volume', 'variacion_relativa', 'variacion_porcentual', 'variacion_logaritmica']]\n",
    "y = df['Adj Close']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "ad05c4bf-7479-4b8e-87b1-310fa85d89a8",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Modelo Ramdom Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "6f9f0eda-c64e-4630-a456-e5070120331c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n[CV] END .max_depth=8, min_samples_split=2, n_estimators=250; total time=  12.6s\n[CV] END .max_depth=8, min_samples_split=2, n_estimators=250; total time=  12.5s\n[CV] END .max_depth=8, min_samples_split=2, n_estimators=250; total time=  12.5s\n[CV] END .max_depth=8, min_samples_split=2, n_estimators=250; total time=  12.6s\n[CV] END .max_depth=8, min_samples_split=2, n_estimators=250; total time=  12.5s\nMSE: 6277.929446086223\nMAE: 52.89989409479736\nRMSE: 79.23338593097118\nR2: 0.4915\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001B[31m2025/11/11 01:57:44 WARNING mlflow.models.model: Model logged without a signature and input example. Please set `input_example` parameter when logging the model to auto infer the model signature.\u001B[0m\n"
     ]
    }
   ],
   "source": [
    "# Definir el experimento\n",
    "experiment_name = \"/Users/js.ramirezg123@uniandes.edu.co/sklearn-diab\"\n",
    "mlflow.set_experiment(experiment_name)\n",
    "\n",
    "rf = RandomForestRegressor(random_state=0)\n",
    "\n",
    "#Parametros\n",
    "param_distributions = {\n",
    "    'n_estimators': [250],\n",
    "    'max_depth': [8],\n",
    "    'min_samples_split': [2],\n",
    "}\n",
    "\n",
    "#Randomized Search\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=rf,\n",
    "    param_distributions=param_distributions,\n",
    "    n_iter=1,  \n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    random_state=0,\n",
    "    verbose=2\n",
    ")\n",
    "\n",
    "# Entrenamiento en MLflow\n",
    "\n",
    "with mlflow.start_run(run_name=\"RandomForest_Experiment_v2\"):\n",
    "    random_search.fit(X_train, y_train)\n",
    "    y_pred = random_search.predict(X_test)\n",
    "\n",
    "    # Métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = mse ** 0.5\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(\"MSE:\", mse)\n",
    "    print(\"MAE:\", mae)\n",
    "    print(\"RMSE:\", rmse)\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "\n",
    "    #Parámetros y métricas en MLflow\n",
    "    mlflow.log_params(random_search.best_params_)\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "    # Guardar el modelo\n",
    "    mlflow.sklearn.log_model(random_search.best_estimator_, \"model_rf\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "4f51f52f-35e7-4354-a6aa-241b4421b02a",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Modelo ARIMA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "1342f8e1-8b53-438f-8f27-8940ad0b675e",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n  self._init_dates(dates, freq)\n/databricks/python/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n  self._init_dates(dates, freq)\n/databricks/python/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:473: ValueWarning: An unsupported index was provided. As a result, forecasts cannot be generated. To use the model for forecasting, use one of the supported classes of index.\n  self._init_dates(dates, freq)\n/databricks/python/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: ValueWarning: No supported index is available. Prediction results will be given with an integer index beginning at `start`.\n  return get_prediction_index(\n/databricks/python/lib/python3.12/site-packages/statsmodels/tsa/base/tsa_model.py:837: FutureWarning: No supported index is available. In the next version, calling this method in a model without a supported index will result in an exception.\n  return get_prediction_index(\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12347.8154\nMAE: 79.7108\nRMSE: 111.1207\nR2: -0.0001\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/11/11 01:59:32 WARNING mlflow.utils.requirements_utils: Failed to run predict on input_example, dependencies introduced in predict are not captured.\nMlflowException('prediction dataframes for a TimeSeriesModel must have exactly one row and include columns called start and end')Traceback (most recent call last):\n  File \"/databricks/python/lib/python3.12/site-packages/mlflow/utils/_capture_modules.py\", line 166, in load_model_and_predict\n    model.predict(input_example, params=params)\n  File \"/databricks/python/lib/python3.12/site-packages/mlflow/statsmodels/__init__.py\", line 362, in predict\n    raise MlflowException(\nmlflow.exceptions.MlflowException: prediction dataframes for a TimeSeriesModel must have exactly one row and include columns called start and end\n2025/11/11 01:59:32 WARNING mlflow.models.model: Failed to validate serving input example {\n  \"dataframe_split\": {\n    \"columns\": [\n      \"y_train_example\"\n    ],\n    \"data\": [\n      [\n        17.443784713745117\n      ],\n      [\n        36.22602844238281\n      ],\n      [\n        27.050926208496094\n      ],\n      [\n        1.5403321981430054\n      ],\n      [\n        251.081787109375\n      ]\n    ]\n  }\n}. Alternatively, you can avoid passing input example and pass model signature instead when logging the model. To ensure the input example is valid prior to serving, please try calling `mlflow.models.validate_serving_input` on the model uri and serving input example. A serving input example can be generated from model input example using `mlflow.models.convert_input_example_to_serving_input` function.\nGot error: Failed to enforce schema of data '   y_train_example\n0        17.443785\n1        36.226028\n2        27.050926\n3         1.540332\n4       251.081787' with schema '['Adj Close': double (required)]'. Error: Model is missing inputs ['Adj Close']. Note that there were extra inputs: ['y_train_example']\n"
     ]
    }
   ],
   "source": [
    "#Entrenar el modelo ARIMA(A, RI, MA) hiperparámetros que definen el orden del modelo\n",
    "p, d, q = 2, 1, 2\n",
    "\n",
    "with mlflow.start_run(run_name=\"ARIMA_Experiment\"):\n",
    "\n",
    "    #Entrenar modelo ARIMA\n",
    "    model = ARIMA(y_train, order=(p, d, q))\n",
    "    model_fit = model.fit()\n",
    "\n",
    "    #Predicciones sobre el conjunto de test\n",
    "    y_pred = model_fit.forecast(steps=len(y_test))\n",
    "\n",
    "    #Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R2: {r2:.4f}\")\n",
    "\n",
    "    #Registrar parámetros y métricas\n",
    "    mlflow.log_param(\"p\", p)\n",
    "    mlflow.log_param(\"d\", d)\n",
    "    mlflow.log_param(\"q\", q)\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "    #Registrar el modelo en MLflow\n",
    "    signature = infer_signature(y_train, y_pred)\n",
    "    input_example = pd.DataFrame({\"y_train_example\": y_train[:5].values})\n",
    "\n",
    "    mlflow.statsmodels.log_model(\n",
    "        model_fit,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {},
     "inputWidgets": {},
     "nuid": "52b09a66-3fe5-4aed-8472-c8a4599da44d",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "source": [
    "### Modelo Regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7f412e47-0b11-4d42-84b3-85d6c9f5c98c",
     "showTitle": false,
     "tableResultSettingsMap": {},
     "title": ""
    }
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12345.6650\nMAE: 79.7032\nRMSE: 111.1110\nR²: 0.0001\n"
     ]
    },
    {
     "output_type": "stream",
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/databricks/python/lib/python3.12/site-packages/mlflow/types/utils.py:452: UserWarning: Hint: Inferred schema contains integer column(s). Integer columns in Python cannot represent missing values. If your input data contains missing values at inference time, it will be encoded as floats and will cause a schema enforcement error. The best way to avoid this problem is to infer the model schema based on a realistic data sample (training dataset) that includes missing values. Alternatively, you can declare integer columns as doubles (float64) whenever these columns may have missing values. See `Handling Integers With Missing Values <https://www.mlflow.org/docs/latest/models.html#handling-integers-with-missing-values>`_ for more details.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#Definir y entrenar el modelo de regresión lineal\n",
    "lr = LinearRegression(positive=True)\n",
    "\n",
    "with mlflow.start_run(run_name=\"LinearRegression_Experiment\"):\n",
    "    #Entrenar modelo\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    #Predicciones\n",
    "    y_pred = lr.predict(X_test)\n",
    "\n",
    "    #Calcular métricas\n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    mae = mean_absolute_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "\n",
    "    # ----------------------------------------------------------------\n",
    "    # 3️⃣ Registrar parámetros, métricas y modelo en MLflow\n",
    "    # ----------------------------------------------------------------\n",
    "    mlflow.log_param(\"fit_intercept\", lr.fit_intercept)\n",
    "    mlflow.log_param(\"normalize\", False)\n",
    "    mlflow.log_metric(\"MSE\", mse)\n",
    "    mlflow.log_metric(\"MAE\", mae)\n",
    "    mlflow.log_metric(\"RMSE\", rmse)\n",
    "    mlflow.log_metric(\"R2\", r2)\n",
    "\n",
    "    # Inferir firma del modelo y ejemplo de entrada\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "    input_example = X_train.iloc[:5]\n",
    "\n",
    "    # Registrar modelo\n",
    "    mlflow.sklearn.log_model(\n",
    "        lr,\n",
    "        artifact_path=\"model\",\n",
    "        signature=signature,\n",
    "        input_example=input_example\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "computePreferences": null,
   "dashboards": [],
   "environmentMetadata": {
    "base_environment": "",
    "environment_version": "4"
   },
   "inputWidgetPreferences": null,
   "language": "python",
   "notebookMetadata": {
    "pythonIndentUnit": 4
   },
   "notebookName": "ML Flow Experiments",
   "widgets": {}
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}